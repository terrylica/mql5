# MQL5 Article Extraction System - Production Guide

## ğŸ¯ Objective

Production-grade system for extracting MQL5 trading articles with:

- Elegant formatting with local images
- Proper MQL5 syntax highlighting
- Batch processing with checkpoints
- Robust error recovery with retry logic
- Quality validation
- Comprehensive logging

**Use Case:** Training data collection for algorithmic trading seq-2-seq models

---

## âš ï¸ Critical Constraints

**NEVER run parallel extractions from MQL5.com** - triggers 24h+ IP blocks.

---

## ğŸ“¦ Setup (First Time)

### **Automated Setup (Recommended)**

```bash
# One-time setup - creates persistent virtual environment
./setup.sh
```

This installs:

- Python virtual environment (`.venv/`)
- All dependencies (playwright, httpx, etc.)
- Playwright Chromium browser

**Total time:** ~30 seconds | **Disk usage:** ~230 MB

### **Manual Setup**

```bash
# Create virtual environment
uv venv

# Install dependencies
uv pip install --python .venv/bin/python -r requirements.txt

# Install Playwright browsers
.venv/bin/python -m playwright install chromium
```

**Why persistent venv?** See [docs/dependency_management.md](docs/dependency_management.md) for `uv` vs `uvx` comparison.

---

## ğŸš€ Quick Start

### **Extract All Articles (Recommended)**

```bash
# Auto-discover and extract all 77 articles
.venv/bin/python mql5_extract.py discover-and-extract

# With options
.venv/bin/python mql5_extract.py discover-and-extract --user-id 29210372 --verbose
```

### **Extract Single Article**

```bash
.venv/bin/python mql5_extract.py single https://www.mql5.com/en/articles/19625
```

### **Batch from File**

```bash
# Create URL file first
.venv/bin/python mql5_extract.py discover-and-extract --save-urls urls.txt --dry-run

# Extract all
.venv/bin/python mql5_extract.py batch urls.txt
```

**Alternative:** Activate venv once, then use `python` directly:

```bash
source .venv/bin/activate  # Activate once per terminal session
.venv/bin/python mql5_extract.py discover-and-extract
```

---

## ğŸ“ System Architecture

### **File Structure**

```
/mql5/
â”œâ”€â”€ mql5_extract.py          # Main CLI (NEW - production interface)
â”œâ”€â”€ config.yaml              # Configuration (NEW)
â”œâ”€â”€ lib/                     # Shared library (NEW)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ extractor.py        # Enhanced extractor with retry
â”‚   â”œâ”€â”€ discovery.py        # URL discovery
â”‚   â”œâ”€â”€ batch_processor.py  # Batch orchestration
â”‚   â”œâ”€â”€ logger.py           # Logging system
â”‚   â””â”€â”€ config_manager.py   # Config management
â”œâ”€â”€ browser_scraper.py      # Legacy (backward compat)
â”œâ”€â”€ simple_mql5_extractor.py # Legacy (backward compat)
â””â”€â”€ simple_extraction_results/ # Output directory
    â””â”€â”€ {user_id}/          # Hierarchical structure
        â””â”€â”€ article_{id}/
            â”œâ”€â”€ article.md
            â”œâ”€â”€ metadata.json
            â”œâ”€â”€ images_manifest.json
            â””â”€â”€ images/
```

### **Output Structure**

```
mql5_articles/
â”œâ”€â”€ 29210372/                 # User folder (numeric ID)
â”‚   â”œâ”€â”€ article_19625/
â”‚   â”‚   â”œâ”€â”€ article.md       # Clean markdown with MQL5 syntax
â”‚   â”‚   â”œâ”€â”€ metadata.json    # Extraction metadata
â”‚   â”‚   â”œâ”€â”€ images_manifest.json
â”‚   â”‚   â””â”€â”€ images/          # Local images
â”‚   â””â”€â”€ article_19624/
â”œâ”€â”€ jslopes/                  # User folder (username)
â”‚   â””â”€â”€ article_19626/
â”œâ”€â”€ gamuchiraindawa/          # User folder (username)
â”‚   â””â”€â”€ article_19383/
â”œâ”€â”€ extraction_summary.json   # Batch statistics
â””â”€â”€ logs/
    â””â”€â”€ extraction.log       # Detailed logs
```

**User Folder Naming**: MQL5 uses dual identifiers - some profiles use numeric IDs (`29210372`), others use usernames (`jslopes`, `gamuchiraindawa`). Both are stable, unique identifiers extracted from the article's author meta tag. This is expected MQL5 behavior, not a bug.

---

## ğŸ”§ Configuration

### **config.yaml**

All settings are configurable via YAML:

```yaml
extraction:
  output_dir: "mql5_articles"
  headless: true # Run browser without UI (anti-detection enabled)
  timeout_ms: 30000 # Page load timeout

retry:
  max_attempts: 3 # Retry failed extractions
  initial_backoff_seconds: 5 # Exponential backoff delay
  exponential_base: 2

batch:
  rate_limit_seconds: 2 # Delay between articles
  checkpoint_file: ".extraction_checkpoint.json"
  resume_on_restart: true # Auto-resume from checkpoint
  continue_on_error: true # Keep going if some fail

logging:
  level: "INFO" # DEBUG, INFO, WARNING, ERROR
  file: "logs/extraction.log"
  console: true

validation:
  min_word_count: 500 # Quality check
  min_code_blocks: 1
  reject_login_popup: true

discovery:
  default_user_id: "29210372" # Allan Munene Mutiiria
```

**Override via CLI:**

```bash
.venv/bin/python mql5_extract.py batch urls.txt --output my_results/ --verbose
```

---

## ğŸ“Š CLI Usage

### **Three Operational Modes:**

#### **1. Single Article**

```bash
# Extract one article
.venv/bin/python mql5_extract.py single https://www.mql5.com/en/articles/19625

# With debugging (show browser)
.venv/bin/python mql5_extract.py single https://... --no-headless --verbose
```

#### **2. Batch Processing**

```bash
# Extract from URL file
.venv/bin/python mql5_extract.py batch urls.txt

# Resume interrupted extraction
.venv/bin/python mql5_extract.py batch urls.txt --resume

# Test with limited articles
.venv/bin/python mql5_extract.py batch urls.txt --max-articles 5

# Custom output directory
.venv/bin/python mql5_extract.py batch urls.txt --output /path/to/output
```

#### **3. Auto-Discovery + Extraction**

```bash
# Discover and extract all articles for user
.venv/bin/python mql5_extract.py discover-and-extract

# For different user
.venv/bin/python mql5_extract.py discover-and-extract --user-id USER_ID

# Save discovered URLs without extracting
.venv/bin/python mql5_extract.py discover-and-extract --save-urls urls.txt --dry-run

# Limited extraction (testing)
.venv/bin/python mql5_extract.py discover-and-extract --max-articles 10
```

### **Common Options**

```bash
--config FILE       # Custom config file (default: config.yaml)
--output DIR        # Override output directory
--headless          # Force headless mode
--no-headless       # Show browser (debugging)
--verbose / -v      # DEBUG level logging
--quiet / -q        # ERROR level only
--dry-run           # Show what would be done
```

---

## âœ¨ Key Features

### **1. Retry Logic with Exponential Backoff**

- Automatically retries failed extractions (3 attempts default)
- Exponential backoff: 5s â†’ 10s â†’ 20s
- Configurable in `config.yaml`

### **2. Checkpoint System**

```bash
# Start extraction
.venv/bin/python mql5_extract.py batch urls.txt

# If interrupted, resume automatically
.venv/bin/python mql5_extract.py batch urls.txt --resume

# Checkpoint file: .extraction_checkpoint.json
```

### **3. Quality Validation**

- Minimum word count (500 default)
- Minimum code blocks (1 default)
- Login popup detection
- Fails fast on invalid content

### **4. Comprehensive Logging**

```bash
# File logging (logs/extraction.log)
# Real-time console output
# Structured with timestamps and article IDs

# Adjust verbosity
.venv/bin/python mql5_extract.py batch urls.txt --verbose    # DEBUG
.venv/bin/python mql5_extract.py batch urls.txt --quiet      # ERROR only
```

### **5. Statistics Generation**

After batch processing, `extraction_summary.json` contains:

```json
{
  "summary": {
    "total": 77,
    "successful": 75,
    "failed": 2,
    "skipped": 0,
    "duration_seconds": 450
  },
  "statistics": {
    "total_words": 402341,
    "total_images": 234,
    "total_code_blocks": 568,
    "unique_users": 5,
    "users": ["29210372", "jslopes", "ssn", "m.aboud", "metaquotes"]
  },
  "failed_articles": [
    { "article_id": "19626", "error": "Timeout after 3 retries" }
  ]
}
```

### **6. Rate Limiting**

- 2-second delay between articles (configurable in `config.yaml`)
- Sequential extraction only - see Critical Constraints

---

## ğŸ¯ Production Workflows

### **Workflow 1: Extract All Articles**

```bash
# One command to rule them all
.venv/bin/python mql5_extract.py discover-and-extract
```

This will:

1. Discover all 77 articles via browser automation
2. Extract each article with retry logic
3. Download all images locally
4. Generate statistics summary
5. Save progress checkpoint after each article

### **Workflow 2: Custom User Extraction**

```bash
# Discover URLs for custom user
.venv/bin/python mql5_extract.py discover-and-extract \
  --user-id jslopes \
  --save-urls jslopes_urls.txt

# Extract with custom config
.venv/bin/python mql5_extract.py batch jslopes_urls.txt \
  --config production.yaml \
  --output jslopes_articles/
```

### **Workflow 3: Resume Failed Run**

```bash
# Start extraction (fails at article 50)
.venv/bin/python mql5_extract.py batch urls.txt

# Check logs
tail -f logs/extraction.log

# Resume from checkpoint
.venv/bin/python mql5_extract.py batch urls.txt --resume
```

### **Workflow 4: Testing & Debugging**

```bash
# Test with 5 articles
.venv/bin/python mql5_extract.py discover-and-extract \
  --max-articles 5 \
  --no-headless \
  --verbose

# Dry run to preview
.venv/bin/python mql5_extract.py batch urls.txt --dry-run
```

---

## ğŸ“Š Quality Verification

### **Check Extraction Results**

````bash
# Count extracted articles
find simple_extraction_results/ -name "article.md" | wc -l

# Check MQL5 syntax highlighting
grep -r "```mql5" simple_extraction_results/ | wc -l

# Check images downloaded
find simple_extraction_results/ -name "*.png" -o -name "*.jpg" | wc -l

# View summary statistics
cat simple_extraction_results/extraction_summary.json
````

### **Validate Individual Article**

```bash
# Check word count
wc -w simple_extraction_results/29210372/article_19625/article.md

# Check images
ls simple_extraction_results/29210372/article_19625/images/

# View metadata
cat simple_extraction_results/29210372/article_19625/metadata.json
```

---

## ğŸ”‘ Technical Details

### **Content Extraction**

- **Target Selector**: `div.content` for article content
- **MQL5 Detection**: HTML `<pre class="code">` elements for 100% accuracy
- **Image Processing**: Automatic download with descriptive filenames
- **Link Handling**: Resolves relative URLs, fixes malformed links
- **Formatting**: BeautifulSoup â†’ Markdown with preserved structure

### **Hierarchical Organization**

- **Top Level**: User folders - numeric ID (e.g., `29210372/`) OR username (e.g., `jslopes/`)
- **Second Level**: Article folders (e.g., `article_19625/`)
- **Files**: Simplified names (`article.md`, `metadata.json`)
- **Traceability**: Full context from folder path
- **Note**: MQL5 profiles use either numeric IDs or usernames in their URLs - both are valid, stable identifiers

### **Error Recovery**

- **Retry Logic**: 3 attempts with exponential backoff
- **Validation**: Quality checks before saving
- **Checkpoint**: Progress saved after each article
- **Continue-on-error**: Batch processing doesn't stop on failures

---

## ğŸ“š Data Source

- **Primary Source**: https://www.mql5.com/en/users/29210372/publications
- **Author**: Allan Munene Mutiiria (77 technical articles)
- **Content Type**: MQL5 trading strategy implementations
- **Total Volume**: ~400,000+ words of technical content
- **Date Range**: Articles from 2021-2025

---

## ğŸ†˜ Troubleshooting

### **Issue: Headless browser blocked (404 or empty page)**

**Fixed in v1.0.0** - Anti-detection enabled by default:

- Realistic user-agent header
- Standard viewport (1920x1080)
- Locale and timezone spoofing

If still encountering issues:

```bash
# Test with visible browser (for debugging only)
.venv/bin/python mql5_extract.py single URL --no-headless
```

### **Issue: Extraction fails with timeout**

```bash
# Increase timeout in config.yaml
extraction:
  timeout_ms: 60000  # 60 seconds

# Or use verbose logging to debug
.venv/bin/python mql5_extract.py single URL --verbose
```

### **Issue: Browser crashes**

```bash
# Run with UI to see what's happening
.venv/bin/python mql5_extract.py single URL --no-headless

# Check system resources
# Playwright requires ~500MB RAM per browser instance
```

### **Issue: Login popup detected**

```bash
# Check if articles are actually public
# Verify URL is correct article link
# Check validation settings in config.yaml
```

### **Issue: Resume not working**

```bash
# Manually load checkpoint
cat .extraction_checkpoint.json

# Clear and restart
rm .extraction_checkpoint.json
.venv/bin/python mql5_extract.py batch urls.txt
```

### **Issue: Bot Detection (HTTP 403/404, "Author not found")**

Stop all extractions, wait 24-48h, extract sequentially with increased delays in `config.yaml`.

---

## ğŸ”„ Migration from Legacy Scripts

### **Old Way**

```bash
uvx --with playwright python browser_scraper.py
uvx --with beautifulsoup4 --with html2text python extract_all_77_articles.py
```

### **New Way**

```bash
.venv/bin/python mql5_extract.py discover-and-extract
```

**Backward Compatibility:**

- `browser_scraper.py` still works
- `simple_mql5_extractor.py` still works
- Both kept for reference/testing

---

## ğŸ“ Summary

### **Production Features Added**

âœ… CLI interface with 3 operational modes
âœ… YAML configuration with CLI overrides
âœ… Comprehensive file + console logging
âœ… Exponential backoff retry logic
âœ… Checkpoint-based resume capability
âœ… Quality validation before saving
âœ… Batch statistics generation
âœ… Rate limiting for respectful scraping
âœ… Hierarchical user_id/article_id organization
âœ… Complete error context and reporting

### **Quick Reference**

```bash
# Extract everything
.venv/bin/python mql5_extract.py discover-and-extract

# Single article
.venv/bin/python mql5_extract.py single URL

# Batch processing
.venv/bin/python mql5_extract.py batch urls.txt

# Resume interrupted
.venv/bin/python mql5_extract.py batch urls.txt --resume

# Help
.venv/bin/python mql5_extract.py --help
.venv/bin/python mql5_extract.py COMMAND --help
```
